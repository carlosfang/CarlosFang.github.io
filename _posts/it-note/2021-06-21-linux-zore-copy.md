---
layout: post
title: linux 零拷贝技术
date: 2021-06-21 20:21:12
categories: Linux 
tags:  系统编程
excerpt: 零拷贝（zero-copy）技术是一种Linux I/O 的读写方式，通过 DMA 控制器提高吞吐率
---

#### 前言

零拷贝（zero-copy）技术是一种Linux I/O 的读写方式。指的是CPU不参与拷贝数据，通过I/O设备的DMA控制器，数据不用再通过用户态的就拷贝到目的地 。

linux 中的零拷贝，`用mmap()`  、`sendfile()`、 DMA gather copy等的方式 ，从而减少数据的拷贝次数。 

开源项目 Kafka 有很高的 `I/O` 吞吐率，其中一个原因是用到了“零拷贝”技术。

#### Linux I/O 读写方式 

Linux对于磁盘与主存之间的数据传输有三种机制， 分别是轮询、I/O 中断以及 DMA 。

- 询方式是基于死循环对 I/O 端口进行不断检测。

- I/O 中断方式是指当数据到达时，磁盘主动向 CPU 发起中断请求，由 CPU 自身负责数据的传输过程。 

- DMA 传输则在 I/O 中断的基础上引入了 DMA 磁盘控制器，由 DMA 磁盘控制器负责数据的传输，降低了 I/O 中断操作对 CPU 资源的大量消耗。




#####  I/O 中断原理

以系统调用`read()`为例. 程序只是一个简单的函数调用，但背面却发生了多次的数据拷贝。如下图。 

1. 进程调用`read()`时，发现系统调用，用户态切换到内核态，进程被阻塞。
2. CPU接到指令后，会磁盘发起IO请求，然后返回。
3. 磁盘把数据放入到磁盘控制器的缓冲区中，然后向CPU发起IO中断信息。
4. CPU收到中断信息后，把数据从磁盘控制器缓冲区拷贝到内核缓冲区。
5. 再将数据从 内核缓冲区拷贝到用户缓冲区。
6. 然后从内核态切换到用户态， `read()`返回。



![](..\..\assets\linux\2021-06-21-linux-zero-copy-001.png)



从这个流程上看，一共发生了两次的数据拷贝，即：将数据从磁盘的控制器缓冲区拷贝到内核缓冲区，将数据从内核缓冲区拷贝到用户缓冲区。这个过程是在内核态进行，CPU参与了数据拷贝。

如果是数据量比较大的传输，那么就仍占用大量的CPU用到拷贝数据，影响机器的性能。



##### DMA 原理

DMA 全称**直接内存访问**（**D**irect **M**emory **A**ccess） 

> 是计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统（电脑外设），可以独立地直接读写系统内存，而不需CPU介入处理 。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。[1]

从这个定义上我们可以看出释放CPU的算力。

DMA技术的运用，改变了传统数据的传输流程。这个流程中比上面的多了一个DMA 角色，处在CPU和磁盘的中间。如下图:

![](..\..\assets\linux\2021-06-21-linux-zero-copy-002.png)

具体过程：

1. CPU向DMA发起IO请求，然后返回。CPU得到释放。

2. DMA再向磁盘发起IO请求，磁盘将数据放入磁盘缓冲区，CPU 不参与此过程。然后通知回DMA。 

3. DMA将数从磁盘的缓冲区拷贝到内核缓冲区。CPU 不参与此过程。

4. DMA拷贝完成后，向CPU发送完成信号。

5. CPU收到中断信息后，将数据从内核缓冲区拷贝到用户缓冲区。CPU参与这个过程的数据拷贝。

   

这个数据的传输流程，加入了DMA角色，帮忙CPU完成数据拷贝，不再占用CPU。CPU只负责通知DMA的干活。

现在。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。所以DMA能不能用，也要看硬件设备。



#### 传统I/O方式

linux的传统I/O方式，是通过`read()`、`write()`两个系统调用完成的。

```c
read(file_fd, tmp_buf, len);
write(socket_fd, tmp_buf, len);
```

程序调用时只是两个很简单的函数调用，便背后也有复杂的数据传输流程。如下图：

![](..\..\assets\linux\2021-06-21-linux-zero-copy-003.png)

具体过程：

1. 程序调用`read()`函数，发起系统调用，从用户态切换到内核态。
2. CPU通知DMA拷贝数据，DMA从硬件的缓冲区中把数据拷贝到内核缓冲区。
3. CPU再数据从内核的缓冲区拷贝到用户缓冲区。 从内核态切换到用户态。
4. 程序调用`write()`函数，发起系统调用，从用户态切换到内核态。
5. CPU把数据拷贝从用户缓冲区socket缓冲区，通知DMA。 
6. DMA把数据从socket缓冲区把数据拷贝到网卡。
7. 完成后返回，从内核态切换用户态。

这个过程，**2次系统调用，4次上下文的切换。2次CPU拷贝，2次DMA拷贝，一共4次拷贝**。

- CPU拷贝：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。
- DMA拷贝：由 CPU 向DMA下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。



#### 零拷贝技术

零拷贝技术在linux的实现主要有 3 个思路：用户态直接 I/O、减少数据拷贝次数以及写时复制技术。



##### 用户态直接 I/O

应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输。这种方式依旧存在用户空间和内核空间的上下文切换，硬件上的数据直接拷贝至了用户空间，不经过内核空间。因此，直接 I/O 不存在内核空间缓冲区和用户空间缓冲区之间的数据拷贝。

![](..\..\assets\linux\2021-06-21-linux-zero-copy-004.png)

应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如**数据库管理系统**就是一个代表。

这种零拷贝机制会直接操作磁盘 I/O，由于 CPU 和磁盘 I/O 之间的执行时间差距，会造成大量资源的浪费，解决方案是配合异步 I/O 使用。

##### mmap() 方式 

这是一种减少数据拷贝次数的方式。linux下，可以使用`mmap()` 、`write()`的方式，替换的`read()`、`write()`方式。`mmap()`在进程空间和内核空间进行了映射，从而使缓冲区的数据可以在用户态和内核态下形成数据共享。 

```c
tmp_buf = mmap(file_fd, len);
write(socket_fd, tmp_buf, len);
```

通过数据共享，减少了CPU的拷贝次数。数据传输的流程变化成如下图：

![](..\..\assets\linux\2021-06-21-linux-zero-copy-005.png)

具体过程：

1. 流程主要的变化是，DMA把数据零拷贝到内核区之后，CPU不用再把数据拷贝到用户空间的缓冲区。这一次由`mmap()`的映射机制共享了内存数据。从而，在这个地方减少了一次的CPU拷贝。

2. `write()`写数据时，从用户空间的缓冲区拷贝数据，其实就是从内核缓冲区拷贝数据，因为数据是共享的。

3. 所以，总的来说，这种方式减少了一次的数据拷贝。


`mmap()`和`write()` 这种方式，数据传输的流程有，4次上下文切换，1次CPU拷贝，2次DMA拷贝。

`mmap()` 主要的于提高对大文件的I/O性能，对于小文件，容易产生内存碎片。 

`mmap()`隐藏了一个并发问题， 当 `mmap()` 一个文件时，如果这个文件被另一个进程所截获，那么 `write()` 系统调用会因为访问非法地址被 `SIGBUS` 信号终止，`SIGBUS` 默认会杀死进程并产生一个  coredump ，服务器可能因此被终止。



##### sendfile() 方式 

Linux2.1版本以后有一个方式 `sendfile()`，不仅减少了拷贝的次数，也减少了上下文的切换次数。 

```c 
sendfile(socket_fd, file_fd, len);
```

这个系统调用目的就是简化网络间的数据传输过程。通过`sendfile()`  ,数据可以内核空间直接被拷贝传输，不用经过用户空间。对于用户态不可见，所以减少了上下文的切换。

![](..\..\assets\linux\2021-06-21-linux-zero-copy-006.png)

具体过程：

1. 进程调用`sendfile()` 后，从用户态切换到内核态，CPU通知DMA 拷贝数据。数据被拷贝到内核缓冲区。

2. CPU再把数据从内核的缓冲区拷贝到Socket缓冲区，这一步并不经过用户缓存区。对用户空间无感知。

3. 再通知DMA把数据拷贝到网卡。

4. 成功后返回，从内核态切换到用户态。

通过`sendfile()`方式，数据传输的过程有：2次上下文的切换，1次CPU的拷贝，2次的DMA拷贝。

  

##### sendfile()  DMA gather copy 方式

Linux 2.4 版本的内核对 `sendfile()` 系统调用进行修改，为 DMA 拷贝引入了 gather 操作。它将内核空间的读缓冲区中对应的数据描述信息（内存地址、地址偏移量）记录到相应的socket缓冲区。由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区（read buffer）拷贝到网卡设备中，这样就省去了内核空间中仅剩的 1 次 CPU 拷贝操作。如图：

![](..\..\assets\linux\2021-06-21-linux-zero-copy-007.png)

具体过程：

1. 进程调用`sendfile()` 后，从用户态切换到内核态，CPU通知DMA 拷贝数据。数据被拷贝到内核缓冲区。
2. CPU只是把内核缓冲区读的缓冲区的文件描述符和数据长度被记录到Socket缓冲区，所以这里并没有发现数据拷贝。
3. DMA从socket缓冲区拿到文件描述符和数据长度后，把数据从内核缓冲区拷贝到网卡。数据并没有通过Socket缓冲区，只有文件描述符和数据长度需要通过Socket缓冲区。
4. 成功后返回，从内核态切换到用户态。

这种方式，用户空间同样无知觉，同时也要硬件scatter-gather 特性支持。同时，它也只适用将文件拷贝socket上会传输。

Linux系统可以查看网卡是否支持scatter-gather 特性。

```text
$ ethtool -k eth0 | grep scatter-gather
scatter-gather: on
```

腾讯的云服务器

```sh
[root@VM-0-15-centos ~]# ethtool -k eth0 | grep scatter-gather
scatter-gather: off
        tx-scatter-gather: off [fixed]
        tx-scatter-gather-fraglist: off [fixed]
```

改不了 scatter-gather

```sh
[root@VM-0-15-centos ~]# ethtool -K eth0 tx-scatter-gather on
Could not change any device features

```


这个过程，有2次上下文的切换，2次DMA拷贝，0次CPU拷贝。



##### splice()方式

`sendfile()` 、DMA gather 拷贝方式要硬件支持，同时也只能在socket上才适用。	

 `splice()` 系统调用，不仅不需要硬件支持，还实现了两个文件描述符之间的数据零拷贝。`splice()` 的伪代码如下：

```cpp
splice(fd_in, off_in, fd_out, off_out, len, flags);
```

Linux  2.6.17 版本引用。

splice 系统调用可以在内核空间的读缓冲区（read buffer）和网络缓冲区（socket buffer）之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。

通过映射页面来工作，实际上并不复制任何数据。[3]

![](..\..\assets\linux\2021-06-21-linux-zero-copy-008.png)

具体过程：

1. 进程调用`splice()` 后，从用户态切换到内核态，CPU通知DMA 拷贝数据。数据被拷贝到内核缓冲区。
2. CPU在内核缓冲区和Socket缓冲区建立成Pipeline。
3. DMA从Socket缓冲区拷贝到网卡。
4. 成功后返回，从内核态切换到用户态。

这个过程，有2次上下文的切换，2次DMA拷贝，0次CPU拷贝。

写时复制技术：写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么将其拷贝到自己的进程地址空间中，如果只是数据读取操作则不需要进行拷贝操作。



##### 几种方式的对比

| 拷贝方式                        | CPU拷贝 | DMA拷贝 | 上下文切换 | 备注                                                         |
| ------------------------------- | :-----: | :-----: | :--------: | ------------------------------------------------------------ |
| `read()` 、 `write()`           |    2    |    2    |     4      | 传统方式                                                     |
| `mmap()`、 `write()`            |    1    |    2    |     4      | 内存映射方式                                                 |
| `sendfile()`                    |    1    |    2    |     2      | linux内核版本2.1以后才有                                     |
| `sendfile()` 、 DMA gather copy |    0    |    2    |     2      | Linux 2.4 版本，硬件支持,只能在socket运用                    |
| `splice()`                      |    0    |    2    |     2      | 内核空间pipeline，通过重新映射页面来工作，实际上并不复制任何数据。 |

`sendfile()` 、 DMA gather copy 和 splice() CPU的拷贝次数已经是0次了。

#### 实现 

写了一个测试程序，`sendfile()`  比`read()` 、 `write()`是要快一点。 对同一个小文件进行读写900w次。

```sh
[root@VM-0-15-centos zorecopy]# ./test_zorecopy test1.txt  test2.txt test3.txt
use_sendfile time is: 35567 ms
use_read_and_write time is: 36985 ms
```

#### 总结

除非你是做基础组件,不然在日常工作中，很多时候,这一些比基础的技术可能不会直接用到。但是，却会时常间接用到。如：我们要选方案，要做出判断那种方案合适，依据是什么。这就要求我们对基础原理所有了解。 再如，这种大原理的优化思路过程。我们可否借鉴，业务需求中数据有多次复制，是否有办法减少复制的次数提高效率。当然，具体问题要具体分析。多了解一些原理拓展知识面，扩大自己的能力圈，可以更好更准确的做判断。



#### 参考

[1] [维基百科-直接内存访问]( https://zh.wikipedia.org/wiki/%E7%9B%B4%E6%8E%A5%E8%A8%98%E6%86%B6%E9%AB%94%E5%AD%98%E5%8F%96)

[2] [splice(2) — Linux manual pag](https://man7.org/linux/man-pages/man2/splice.2.html)

[3] [wiki - splice (system call)](https://en.wikipedia.org/wiki/Splice_(system_call))

